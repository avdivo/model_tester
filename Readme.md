# Тестировщик моделей
Тестирование моделей с разными промптами и запросами. 
- выбор поставщика моделей, модели и основных параметров запроса
- выбор промпта и списка вопросов и ответов (в одном файле)
- автоматический прогон тестов
- замер времени для каждого запроса
- отчет в консоли и в файлах

## Настройка теста
1. Файлы с названием/описанием теста, промптом, вопросами и ответами хранятся в папке tests в формате:
``` markdawn
# Описание
Тут короткий текст с описанием теста

# Промпт
Промпт в текстовом формате или md

# Тесты
## Вопрос 1
Текст запроса к LLM
## Ответ 1
Ответ в формате str. Можно чистый json, 
тогда предполагается что вопос и ответ можно перевести в dict и сравнить.
```
2. Название модели и все параметры задаются прямо в main.py:


## Результаты тестирования
Результаты тестов выводятся в консоль и записываются в файл с 
названием модели (если его нет, то создается) в папке result.  
В для каждого теста выводится следующая информация:

- Дата/время
- Модель
- Цена (ввод), Цена (вывод)
- Название теста (имя файла теста)
- Описание теста

- Вопрос 1
- Ответ 1 от модели
- Ответ 1 контрольный
- Токенов вход
- Токенов выход
- Цена запроса
- Продолжительность запроса

- Токенов вход потрачено на тест
- Токенов выход потрачено на тест
- Общая цена за весь тест
- Общее время потраченное на тест

### Вопрос/ответ
По контрольному ответу оценивается возможность перевода ответа в json.
Если контрольный ответ сам переводится, то и ответ модели должен переводиться.
После чего словари сравниваются и выводится результат: РАВНЫ/НЕ РАВНЫ.
Выводятся 2 словаря для сравнения.
Если ответ модели не переводится в json он выводится как есть, 
сравнения не происходит.

