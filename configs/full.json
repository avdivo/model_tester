{
  "param": {
    "temperature": 0.8,
    "max_tokens": 2048,
    "top_p": 0.9,
    "frequency_penalty": 0.5,
    "presence_penalty": 0.5,
    "seed": 42,
    "stop": [
      "\n"
    ],
    "stream": false
  },
  "response_format": {
    "type": "json_object"
  },
  "extra_body": {
    "provider": {
      "allow_fallbacks": false
    },
    "transforms": [
      "llama-3-tokenizer"
    ],
    "route": "fallback"
  }
}